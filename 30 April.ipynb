{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0f5139-0811-4f89-816c-f10c0e63142d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a \\n   single class. A clustering result satisfies completeness if all the data points that are members of a given class are\\n   elements of the same cluster.\\n   One commonly used method to find the optimal number of clusters is the elbow method, which plots the sum of squared\\n   Euclidean distances between data points and their cluster center and chooses the number of clusters where the change \\n   in the sum of squared distances begins to level off.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a \n",
    "   single class. A clustering result satisfies completeness if all the data points that are members of a given class are\n",
    "   elements of the same cluster.\n",
    "   One commonly used method to find the optimal number of clusters is the elbow method, which plots the sum of squared\n",
    "   Euclidean distances between data points and their cluster center and chooses the number of clusters where the change \n",
    "   in the sum of squared distances begins to level off.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524204bb-1f73-4ae4-a390-b22cbc9452bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The V-measure is the harmonic mean between homogeneity and \\n   completeness:\\n                 v = (1 + beta) * homogeneity * completeness / (beta * homogeneity + completeness) \\nThis metric is independent of the absolute values of the labels: a permutation of the class or cluster label values\\nwon't change the score value in any way.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "'''The V-measure is the harmonic mean between homogeneity and \n",
    "   completeness:\n",
    "                 v = (1 + beta) * homogeneity * completeness / (beta * homogeneity + completeness) \n",
    "This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values\n",
    "won't change the score value in any way.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da169cf-695a-4361-892e-1569b483ff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Another metric to evaluate the quality of clustering is referred to as silhouette analysis. Silhouette analysis can be\\n   applied to other clustering algorithms as well. Silhouette coefficient ranges between −1 and 1, where a higher \\n   silhouette coefficient refers to a model with more coherent clusters.\\n   Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot\\n   displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a\\n   way to assess parameters like number of clusters visually.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''Another metric to evaluate the quality of clustering is referred to as silhouette analysis. Silhouette analysis can be\n",
    "   applied to other clustering algorithms as well. Silhouette coefficient ranges between −1 and 1, where a higher \n",
    "   silhouette coefficient refers to a model with more coherent clusters.\n",
    "   Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot\n",
    "   displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a\n",
    "   way to assess parameters like number of clusters visually.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22853f10-a5b4-49bf-b68b-fda2383c5412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Davies-Bouldin Index is defined as the average similarity measure of each cluster with its most similar cluster.\\n   Similarity is the ratio of within-cluster distances to between-cluster distances. In this way, clusters which are \\n   farther apart and less dispersed will lead to a better score.\\n   The Davies-Bouldin index (DBI) is a metric for assessing the separation and compactness of clusters. It is based on\\n   the idea that good clusters are those that have low within-cluster variation and high between-cluster separation.\\n   The Davies–Bouldin index (DBI), introduced by David L. Davies and Donald W. Bouldin in 1979, is a metric for \\n   evaluating clustering algorithms. This is an internal evaluation scheme, where the validation of how well the \\n   clustering has been done is made using quantities and features inherent to the dataset.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''The Davies-Bouldin Index is defined as the average similarity measure of each cluster with its most similar cluster.\n",
    "   Similarity is the ratio of within-cluster distances to between-cluster distances. In this way, clusters which are \n",
    "   farther apart and less dispersed will lead to a better score.\n",
    "   The Davies-Bouldin index (DBI) is a metric for assessing the separation and compactness of clusters. It is based on\n",
    "   the idea that good clusters are those that have low within-cluster variation and high between-cluster separation.\n",
    "   The Davies–Bouldin index (DBI), introduced by David L. Davies and Donald W. Bouldin in 1979, is a metric for \n",
    "   evaluating clustering algorithms. This is an internal evaluation scheme, where the validation of how well the \n",
    "   clustering has been done is made using quantities and features inherent to the dataset.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d56eea7-ce24-4f7d-87d1-b3776ed9fa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a\\n   single class. A clustering result satisfies completeness if all the data points that are members of a given class are\\n   elements of the same cluster.\\n   In homogeneous clusters, all machines are assumed to be the same; however, in the heterogeneous type, machines have\\n   different computing and consumption power. All-in strategy (AIS) [70] is a framework for energy management in \\n   MapReduce clusters by powering down all nodes in the cluster during a low utilization period\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5\n",
    "'''A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a\n",
    "   single class. A clustering result satisfies completeness if all the data points that are members of a given class are\n",
    "   elements of the same cluster.\n",
    "   In homogeneous clusters, all machines are assumed to be the same; however, in the heterogeneous type, machines have\n",
    "   different computing and consumption power. All-in strategy (AIS) [70] is a framework for energy management in \n",
    "   MapReduce clusters by powering down all nodes in the cluster during a low utilization period\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63fb57a-281c-42f0-9a6c-abbc0d3ab5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The silhouette coefficient may provide a more objective means to determine the optimal number of clusters. This is\\n   done by simply calculating the silhouette coefficient over a range of k, and identifying the peak as the optimum K.\\n   The optimal number of clusters can be defined as follow:\\n1. Compute clustering algorithm (e.g., k-means clustering) for different values of k.\\n2. For each k, calculate the total within-cluster sum of square (wss).\\n3. Plot the curve of wss according to the number of clusters k.\\n   The V-measure is the harmonic mean between homogeneity and \\n   completeness: \\n               v = (1 + beta) * homogeneity * completeness / (beta * homogeneity + completeness) \\nThis metric is independent of the absolute values of the labels: \\n           a permutation of the class or cluster label values won't change the score value in any way.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "'''The silhouette coefficient may provide a more objective means to determine the optimal number of clusters. This is\n",
    "   done by simply calculating the silhouette coefficient over a range of k, and identifying the peak as the optimum K.\n",
    "   The optimal number of clusters can be defined as follow:\n",
    "1. Compute clustering algorithm (e.g., k-means clustering) for different values of k.\n",
    "2. For each k, calculate the total within-cluster sum of square (wss).\n",
    "3. Plot the curve of wss according to the number of clusters k.\n",
    "   The V-measure is the harmonic mean between homogeneity and \n",
    "   completeness: \n",
    "               v = (1 + beta) * homogeneity * completeness / (beta * homogeneity + completeness) \n",
    "This metric is independent of the absolute values of the labels: \n",
    "           a permutation of the class or cluster label values won't change the score value in any way.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da31a41-205b-41fc-b084-54306c5e0523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Silhouette method\\n   The advantage of this method is that it can capture the compactness and separation of clusters better than the SSE.\\n   the advantages of silhouette analysis\\n   Silhouette analysis can be used to study the separation distance between the resulting clusters and can be considered \\n   a better method compared to the Elbow method. Silhouette analysis also has added advantage to find the outliers if\\n   present in a cluster\\n   \\n   The disadvantage is that it can be computationally expensive and sensitive to outliers.\\n   the disadvantage of silhouette coefficient\\n   Drawbacks. The Silhouette Coefficient is generally higher for convex clusters than other concepts of clusters, such as\\n   density based clusters like those obtained through DBSCAN.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7\n",
    "'''Silhouette method\n",
    "   The advantage of this method is that it can capture the compactness and separation of clusters better than the SSE.\n",
    "   the advantages of silhouette analysis\n",
    "   Silhouette analysis can be used to study the separation distance between the resulting clusters and can be considered \n",
    "   a better method compared to the Elbow method. Silhouette analysis also has added advantage to find the outliers if\n",
    "   present in a cluster\n",
    "   \n",
    "   The disadvantage is that it can be computationally expensive and sensitive to outliers.\n",
    "   the disadvantage of silhouette coefficient\n",
    "   Drawbacks. The Silhouette Coefficient is generally higher for convex clusters than other concepts of clusters, such as\n",
    "   density based clusters like those obtained through DBSCAN.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5232ec8a-a4e2-435e-9a1c-10b980248c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Davies-Bouldin Index is defined as the average similarity measure of each cluster with its most similar cluster. \\n   Similarity is the ratio of within-cluster distances to between-cluster distances. In this way, clusters which are\\n   farther apart and less dispersed will lead to a better score.\\n   Davies Bouldin index is calculated as the average similarity of each Cluster (say Ci) to its most similar Cluster\\n   (say Cj). This Davies Bouldin index represents the average 'similarity' of clusters, where similarity is a measure\\n   that relates cluster distance to cluster size.\\n   \\n   Disadvantages of clustering are complexity and inability to recover from database corruption. In a clustered \\n   environment, the cluster uses the same IP address for Directory Server and Directory Proxy Server, regardless of which\\n   cluster node is actually running the service.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8\n",
    "'''The Davies-Bouldin Index is defined as the average similarity measure of each cluster with its most similar cluster. \n",
    "   Similarity is the ratio of within-cluster distances to between-cluster distances. In this way, clusters which are\n",
    "   farther apart and less dispersed will lead to a better score.\n",
    "   Davies Bouldin index is calculated as the average similarity of each Cluster (say Ci) to its most similar Cluster\n",
    "   (say Cj). This Davies Bouldin index represents the average 'similarity' of clusters, where similarity is a measure\n",
    "   that relates cluster distance to cluster size.\n",
    "   \n",
    "   Disadvantages of clustering are complexity and inability to recover from database corruption. In a clustered \n",
    "   environment, the cluster uses the same IP address for Directory Server and Directory Proxy Server, regardless of which\n",
    "   cluster node is actually running the service.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baffb5f7-64cd-429c-b82c-bd2f1c12cf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a \\n   single class. A clustering result satisfies completeness if all the data points that are members of a given class are\\n   elements of the same cluster.\\n   This score is a measure between 0–1 that actually quantifies the goodness of the clustering partition. In fact, it \\n   requires that both homogeneity h and completeness c are maximised (NMI is 1 when both h and c are 1). Moreover if the\\n   clustering doesn't satisfy any of the two conditions NMI will be zero.\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9\n",
    "'''A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a \n",
    "   single class. A clustering result satisfies completeness if all the data points that are members of a given class are\n",
    "   elements of the same cluster.\n",
    "   This score is a measure between 0–1 that actually quantifies the goodness of the clustering partition. In fact, it \n",
    "   requires that both homogeneity h and completeness c are maximised (NMI is 1 when both h and c are 1). Moreover if the\n",
    "   clustering doesn't satisfy any of the two conditions NMI will be zero.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10d572ec-353b-4441-a218-ef4246f3e3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Another metric to evaluate the quality of clustering is referred to as silhouette analysis. Silhouette analysis can be\\n   applied to other clustering algorithms as well. Silhouette coefficient ranges between −1 and 1, where a higher \\n   silhouette coefficient refers to a model with more coherent clusters.\\n   The silhouette coefficient or silhouette score kmeans is a measure of how similar a data point is within-cluster \\n   (cohesion) compared to other clusters (separation). The Silhouette score can be easily calculated in Python using the\\n   metrics module of the scikit-learn/sklearn library.\\n   The Silhouette Coefficient is calculated using the mean intra-cluster distance ( a ) and the mean nearest-cluster\\n   distance ( b ) for each sample. \\n   The Silhouette Coefficient for a sample is (b - a) / max(a, b) .\\n   To clarify, b is the distance between a sample and the nearest cluster that the sample is not a part of.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10\n",
    "'''Another metric to evaluate the quality of clustering is referred to as silhouette analysis. Silhouette analysis can be\n",
    "   applied to other clustering algorithms as well. Silhouette coefficient ranges between −1 and 1, where a higher \n",
    "   silhouette coefficient refers to a model with more coherent clusters.\n",
    "   The silhouette coefficient or silhouette score kmeans is a measure of how similar a data point is within-cluster \n",
    "   (cohesion) compared to other clusters (separation). The Silhouette score can be easily calculated in Python using the\n",
    "   metrics module of the scikit-learn/sklearn library.\n",
    "   The Silhouette Coefficient is calculated using the mean intra-cluster distance ( a ) and the mean nearest-cluster\n",
    "   distance ( b ) for each sample. \n",
    "   The Silhouette Coefficient for a sample is (b - a) / max(a, b) .\n",
    "   To clarify, b is the distance between a sample and the nearest cluster that the sample is not a part of.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3b4ee76-0046-488f-b1fa-2a9d2f11ebc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Davies-Bouldin Index is defined as the average similarity measure of each cluster with its most similar cluster.\\n   Similarity is the ratio of within-cluster distances to between-cluster distances. In this way, clusters which are \\n   farther apart and less dispersed will lead to a better score.\\n   The Davies-Bouldin index (DBI) is a metric for assessing the separation and compactness of clusters. It is based\\n   on the idea that good clusters are those that have low within-cluster variation and high between-cluster separation.\\n   Davies Bouldin index is calculated as the average similarity of each Cluster (say Ci) to its most similar Cluster\\n   (say Cj). This Davies Bouldin index represents the average 'similarity' of clusters, where similarity is a measure \\n   that relates cluster distance to cluster size.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q11\n",
    "'''The Davies-Bouldin Index is defined as the average similarity measure of each cluster with its most similar cluster.\n",
    "   Similarity is the ratio of within-cluster distances to between-cluster distances. In this way, clusters which are \n",
    "   farther apart and less dispersed will lead to a better score.\n",
    "   The Davies-Bouldin index (DBI) is a metric for assessing the separation and compactness of clusters. It is based\n",
    "   on the idea that good clusters are those that have low within-cluster variation and high between-cluster separation.\n",
    "   Davies Bouldin index is calculated as the average similarity of each Cluster (say Ci) to its most similar Cluster\n",
    "   (say Cj). This Davies Bouldin index represents the average 'similarity' of clusters, where similarity is a measure \n",
    "   that relates cluster distance to cluster size.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ffce877-a4af-4378-b2f9-c8a2a954fc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Silhouette Coefficient\\n   N−1) and plotted. The user selects the k with the maximum silhouette coefficient. This can be used with any distance \\n   metric and does not require the computation of cluster centers, making it ideal to validate hierarchical clustering.\\n   Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot \\n   displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a\\n   way to assess parameters like number of clusters visually.\\n   Another metric to evaluate the quality of clustering is referred to as silhouette analysis. Silhouette analysis can be\\n   applied to other clustering algorithms as well. Silhouette coefficient ranges between −1 and 1, where a higher\\n   silhouette coefficient refers to a model with more coherent clusters.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q12\n",
    "'''Silhouette Coefficient\n",
    "   N−1) and plotted. The user selects the k with the maximum silhouette coefficient. This can be used with any distance \n",
    "   metric and does not require the computation of cluster centers, making it ideal to validate hierarchical clustering.\n",
    "   Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot \n",
    "   displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a\n",
    "   way to assess parameters like number of clusters visually.\n",
    "   Another metric to evaluate the quality of clustering is referred to as silhouette analysis. Silhouette analysis can be\n",
    "   applied to other clustering algorithms as well. Silhouette coefficient ranges between −1 and 1, where a higher\n",
    "   silhouette coefficient refers to a model with more coherent clusters.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd732c32-f197-46dc-b7f3-fda154562109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
